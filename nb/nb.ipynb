{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('../datasets/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Разделение данных на признаки и целевую переменную\n",
    "X_train = train_data.drop('Outcome', axis=1)\n",
    "y_train = train_data['Outcome']\n",
    "X_test = test_data.drop('Outcome', axis=1)\n",
    "y_test = test_data['Outcome']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Вычисление математического ожидания и дисперсии для каждого класса\n",
    "means = X_train.groupby(y_train).mean()\n",
    "variances = X_train.groupby(y_train).var()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Pregnancies     Glucose  BloodPressure  SkinThickness    Insulin  \\\n",
      "Outcome                                                                     \n",
      "0           3.241895  110.214464      68.309227      19.748130  72.254364   \n",
      "1           4.685446  140.887324      71.497653      21.624413  98.727700   \n",
      "\n",
      "               BMI  DiabetesPedigreeFunction        Age  \n",
      "Outcome                                                  \n",
      "0        30.256608                  0.431254  30.556110  \n",
      "1        35.234272                  0.540545  37.333333  \n",
      "         Pregnancies      Glucose  BloodPressure  SkinThickness       Insulin  \\\n",
      "Outcome                                                                         \n",
      "0           9.158840   678.328890     312.044140     212.618903  10233.220137   \n",
      "1          13.093985  1070.185357     395.534193     285.301665  19298.010408   \n",
      "\n",
      "               BMI  DiabetesPedigreeFunction         Age  \n",
      "Outcome                                                   \n",
      "0        56.834362                  0.094310  122.837469  \n",
      "1        49.758584                  0.142307  120.723270  \n"
     ]
    }
   ],
   "source": [
    "print(means)\n",
    "print(variances)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def product(iterable):\n",
    "    result = 1\n",
    "    for x in iterable:\n",
    "        result *= x\n",
    "    return result\n",
    "\n",
    "def gaussian_naive_bayes(X, means, variances):\n",
    "    likelihoods = [\n",
    "        (2.71828 ** (-((x - mean)**2) / (2 * variance))) / ((2 * 3.14159 * variance) ** 0.5)\n",
    "        for x, mean, variance in zip(X, means, variances)\n",
    "    ]\n",
    "    return product(likelihoods)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for index, row in X_test.iterrows():\n",
    "    posteriors = []\n",
    "    for outcome in means.index:\n",
    "        prior = len(y_train[y_train == outcome]) / len(y_train)\n",
    "        likelihood = gaussian_naive_bayes(row, means.loc[outcome], variances.loc[outcome])\n",
    "        posterior = prior * np.sum(np.log(likelihood))  # используем np.sum вместо np.prod\n",
    "        posteriors.append(posterior)\n",
    "    predictions.append(np.argmax(posteriors))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность наивного байесовского классификатора: 0.36\n"
     ]
    }
   ],
   "source": [
    "# Вычисление точности\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Точность наивного байесовского классификатора по гаусу: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность наивного байесовского классификатора: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Redmi\\AppData\\Local\\Temp\\ipykernel_9556\\1870624265.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exponent = exp(-(X.iloc[i] - means[i])**2 / (2 * variances[i]))\n",
      "C:\\Users\\Redmi\\AppData\\Local\\Temp\\ipykernel_9556\\1870624265.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  likelihood = (1 / (sqrt(2 * pi * variances[i]))) * exponent\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from math import exp, sqrt, pi, log\n",
    "\n",
    "def calculate_prior(y):\n",
    "    class_counts = defaultdict(int)\n",
    "    for label in y:\n",
    "        class_counts[label] += 1\n",
    "    total_samples = len(y)\n",
    "    prior = {label: count / total_samples for label, count in class_counts.items()}\n",
    "    return prior\n",
    "\n",
    "def calculate_likelihood(X, means, variances):\n",
    "    likelihoods = []\n",
    "    for i in range(len(means)):\n",
    "        exponent = exp(-(X.iloc[i] - means[i])**2 / (2 * variances[i]))\n",
    "        likelihood = (1 / (sqrt(2 * pi * variances[i]))) * exponent\n",
    "        likelihoods.append(likelihood)\n",
    "    return likelihoods\n",
    "\n",
    "def fit(X, y):\n",
    "    classes = list(set(y))\n",
    "    class_means = {label: [] for label in classes}\n",
    "    class_variances = {label: [] for label in classes}\n",
    "\n",
    "    for label in classes:\n",
    "        class_data = X[y == label]\n",
    "        class_means[label] = class_data.mean()\n",
    "        class_variances[label] = class_data.var()\n",
    "\n",
    "    return class_means, class_variances, calculate_prior(y)\n",
    "\n",
    "def predict(sample, class_means, class_variances, prior):\n",
    "    posteriors = {}\n",
    "    for label, prior_prob in prior.items():\n",
    "        means = class_means[label]\n",
    "        variances = class_variances[label]\n",
    "        likelihoods = calculate_likelihood(sample, means, variances)\n",
    "        posterior = prior_prob * exp(sum([log(likelihood) for likelihood in likelihoods]))\n",
    "        posteriors[label] = posterior\n",
    "\n",
    "    return max(posteriors, key=posteriors.get)\n",
    "\n",
    "# Используем данные\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train_data.drop('Outcome', axis=1)\n",
    "y_train = train_data['Outcome']\n",
    "X_test = test_data.drop('Outcome', axis=1)\n",
    "y_test = test_data['Outcome']\n",
    "\n",
    "class_means, class_variances, prior = fit(X_train, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "predictions = [predict(sample, class_means, class_variances, prior) for _, sample in X_test.iterrows()]\n",
    "\n",
    "# Вычисление точности\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Точность наивного байесовского классификатора: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. **`calculate_prior(y)`**:\n",
    "\n",
    "   Априорная вероятность для класса \\(c\\) вычисляется как:\n",
    "\n",
    "   \\[ P(Y = c) = \\frac{\\text{Количество образцов класса } c}{\\text{Общее количество образцов}} \\]\n",
    "\n",
    "   где \\(Y\\) - целевая переменная (класс), \\(c\\) - конкретный класс.\n",
    "\n",
    "2. **`calculate_likelihood(X, means, variances)`**:\n",
    "\n",
    "   Вероятность для каждого признака \\(X_i\\) в классе \\(c\\) вычисляется с использованием нормального распределения:\n",
    "\n",
    "   \\[ P(X_i \\mid Y = c) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(X_i - \\mu)^2}{2\\sigma^2}} \\]\n",
    "\n",
    "   где \\(\\mu\\) - среднее значение, \\(\\sigma^2\\) - дисперсия для признака \\(X_i\\) в классе \\(c\\).\n",
    "\n",
    "3. **`fit(X, y)`**:\n",
    "\n",
    "   В этой функции вычисляются средние \\(\\mu\\) и дисперсии \\(\\sigma^2\\) для каждого признака \\(X_i\\) и каждого класса \\(c\\).\n",
    "\n",
    "4. **`predict(sample, class_means, class_variances, prior)`**:\n",
    "\n",
    "   Апостериорная вероятность для класса \\(c\\) при заданном образце \\(X\\) вычисляется как:\n",
    "\n",
    "   \\[ P(Y = c \\mid X) \\propto P(Y = c) \\prod_{i=1}^{n} P(X_i \\mid Y = c) \\]\n",
    "\n",
    "   где \\(n\\) - количество признаков.\n",
    "\n",
    "   В данной реализации используется логарифмирование для избежания численных проблем:\n",
    "\n",
    "   \\[ \\log P(Y = c \\mid X) \\propto \\log P(Y = c) + \\sum_{i=1}^{n} \\log P(X_i \\mid Y = c) \\]\n",
    "\n",
    "5. **Использование данных**:\n",
    "\n",
    "   Здесь данные разделяются на обучающую и тестовую выборки. Обучается модель с использованием `fit`, а затем делаются предсказания с использованием `predict`. Вычисляется точность предсказаний с помощью `accuracy_score`.\n",
    "\n",
    "Общий принцип наивного байесовского классификатора заключается в предположении о независимости признаков при заданном классе и использовании этого предположения для вычисления апостериорных вероятностей. В данном случае, используются нормальные распределения для вычисления вероятностей.\n",
    "\n",
    "\n",
    "### Гауссовский наивный байесовский классификатор (Gaussian Naive Bayes):\n",
    "\n",
    "Тип данных: Подходит для непрерывных числовых данных.\n",
    "Предположение: Предполагает, что каждый признак имеет нормальное распределение внутри каждого класса.\n",
    "Формула: Использует плотность вероятности нормального распределения для оценки вероятности каждого значения признака для каждого класса.\n",
    "Примеры применения: Когда признаки в данных представляют собой непрерывные числовые значения, такие как рост, вес, температура и т. д.\n",
    "\n",
    "\n",
    "### Мультиномиальный наивный байесовский классификатор (Multinomial Naive Bayes):\n",
    "\n",
    "Тип данных: Подходит для данных с дискретными признаками, как правило, это частоты или счетчики.\n",
    "Предположение: Предполагает, что данные представляют собой распределение категорий.\n",
    "Формула: Использует мультиномиальное распределение для вычисления вероятности каждого значения признака для каждого класса.\n",
    "Примеры применения: Когда признаки представляют собой дискретные значения, такие как количество слов в документе, категории товаров и т. д."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
